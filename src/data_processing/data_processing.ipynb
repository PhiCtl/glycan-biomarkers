{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bb827ec-c656-4a32-997d-52e4ba08bd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as plx\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac3d1720-8116-4857-bea9-04c0fb7a6fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../../data/input\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686cc602-335a-4f10-aaf0-6bf39cfa58d2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b151b613-7bfa-4559-9174-7a6ed384601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify QC samples for median normalization correction later on\n",
    "# A subbatch is defined as the samples batch between 2 QC pools.\n",
    "\n",
    "def subbatch(x):\n",
    "    if x['order'] <= 14 :\n",
    "        return 0\n",
    "    if x['order'] <= 26 :\n",
    "        return 1\n",
    "    if x['order'] <= 38 :\n",
    "        return 2\n",
    "    if x['order'] <= 50 :\n",
    "        return 3\n",
    "    if x['order'] <= 62 :\n",
    "        return 4\n",
    "    if x['order'] <= 74 :\n",
    "        return 5\n",
    "    if x['order'] <= 86 :\n",
    "        return 6\n",
    "    if x['order'] <= 101 :\n",
    "        return 7\n",
    "    else:\n",
    "        return 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4350ec7-b8c3-4bab-aa36-3a25d65e2757",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv(os.path.join(DATA_PATH, 'internship_data_matrix.csv'))\n",
    "df_feature_meta = pd.read_csv(os.path.join(DATA_PATH, 'internship_feature_metadata.csv'))\n",
    "df_acq = pd.read_csv(os.path.join(DATA_PATH, 'internship_acquisition_list.csv'))\n",
    "\n",
    "# Augment dataset with metadata\n",
    "df_acq['sub_batch'] = df_acq.apply(lambda x : subbatch(x), axis=1)\n",
    "df_data = df_data.merge(df_acq[['sample', 'class', 'order', 'batch', 'sub_batch']], on='sample')\n",
    "df_data = df_data.melt(id_vars=['sample', 'class', 'order', 'batch', 'sub_batch'],value_name='intensity', var_name='feature')\n",
    "df_data['feature_number'] = df_data['feature'].apply(lambda s : int(s.split('-')[1]))\n",
    "\n",
    "# Filter classes, batch of interest and mass range of interest\n",
    "df_data = df_data[df_data['class'].isin(['QC', 'Dunn', 'French', 'LMU']) & df_data['batch'] == 1]\n",
    "df_glycans = df_feature_meta[df_feature_meta['mz'] > 500]\n",
    "df_data = df_data.merge(df_glycans['feature'], on='feature', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd46bdde-4599-462f-ba50-efd8c36dcdcc",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899e9583-0e71-4061-80f3-32baeadea2e3",
   "metadata": {},
   "source": [
    "## Rescale data to improve comparability\n",
    "\n",
    "There are several ways to proceed.\n",
    "* Global scaling normalization coefficient : ratio of peptide abundance to median peptide abundance measured across all samples\n",
    "* Median pool normalisation : ratio of peptide abundance to median peptide abundance in the three neighbouring QCs. This approach is preferred as it acounts for intra batch effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3a1e4c0-f509-4940-847a-a3d471c38d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the QC pool metabolites median intensities for each data sub_batch\n",
    "pools_medians = df_data[df_data['class'] == 'QC'].groupby(['sub_batch', 'feature'])['intensity'].median().reset_index()\n",
    "pools_medians = pools_medians.sort_values(['feature', 'sub_batch'])\\\n",
    "                             .groupby('feature')\\\n",
    "                             .rolling(3, min_periods=3, center=True).median().dropna()\\\n",
    "                             .reset_index('feature').rename(columns={'intensity' : 'med_QC_intensity'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db7154c6-224f-41b0-ba6b-1d200fe0ae57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data intensities\n",
    "df_data_corr = df_data[df_data['class'].isin(['Dunn', 'LMU', 'French'])].merge(pools_medians, on=['feature', 'sub_batch'])\n",
    "df_data_corr['intensity_corr'] = df_data_corr['intensity'] / df_data_corr['med_QC_intensity']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2227b70c-7071-4fb8-a233-eb18ea722905",
   "metadata": {},
   "source": [
    "## Select features which have a limited variability across samples of the same class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dc0210fc-d044-49b2-9f4a-247445ed995c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before outliers removal, there are 2728 samples\n",
      "After outliers removal, there are 2592 samples\n"
     ]
    }
   ],
   "source": [
    "# Remove outliers in QC to compute robust CV on features using Inter quartile range \n",
    "\n",
    "df_QC = df_data[df_data['class'] == 'QC']\n",
    "df_QC_summary = df_QC.groupby(['feature'])['intensity'].describe().reset_index()\n",
    "df_QC_summary['lower_IQ'] = - 1.5 * df_QC_summary['75%'] + 2.5 * df_QC_summary['25%']\n",
    "df_QC_summary['higher_IQ'] = - 1.5 * df_QC_summary['25%'] + 2.5 * df_QC_summary['75%']\n",
    "print(f\"Before outliers removal, there are {df_QC.shape[0]} samples.\")\n",
    "\n",
    "df_QC = df_QC.merge(df_QC_summary[['feature', 'lower_IQ', 'higher_IQ']], on='feature')\n",
    "df_QC = df_QC[(df_QC['intensity'] >= df_QC['lower_IQ']) & (df_QC['intensity'] <= df_QC['higher_IQ']) ]\n",
    "print(f\"After outliers removal, there are {df_QC.shape[0]} samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "81ef1cfb-6e04-4c31-958c-0d92f09d590a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CV%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>248.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20.206194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.235200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.416975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>14.056512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>17.015310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22.907125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99.131709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              CV%\n",
       "count  248.000000\n",
       "mean    20.206194\n",
       "std     12.235200\n",
       "min      2.416975\n",
       "25%     14.056512\n",
       "50%     17.015310\n",
       "75%     22.907125\n",
       "max     99.131709"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute CV\n",
    "\n",
    "cv_QC = df_QC.groupby('feature')['intensity'].agg(lambda x : x.std() / x.mean() * 100).reset_index().rename(columns={'intensity' : 'CV%'})\n",
    "cv_QC.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb10e8f-7000-477c-a3b5-fc9cdff1a6ee",
   "metadata": {},
   "source": [
    "According to [Instrumental Drift in Untargeted Metabolomics: Optimizing Data Quality with Intrastudy QC Samples](https://pmc.ncbi.nlm.nih.gov/articles/PMC10222478/#sec4-metabolites-13-00665), a accepted CV threshold for biomarker discovery is 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "01041190-8f95-4a5d-a5cf-fc7e6be55564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At this stage, 166 features were selected\n"
     ]
    }
   ],
   "source": [
    "# Select features which exhibit limited variability in QC\n",
    "\n",
    "selected_feats = list(cv_QC[cv_QC['CV%'] <= 20]['feature'])\n",
    "print(f\"At this stage, {len(selected_feats)} features were selected\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml-internships)",
   "language": "python",
   "name": "ml-internships"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
