{
  "data": {
    "data_dir_1": "data/input",
    "data_dir_2": "data/glycan_embedding"
  },


  "results": {
    "models_dir": "/models/",
    "results_dir": "outputs/"
  },


  "plotting": {
    "seaborn_style": "darkgrid",
    "context": "notebook",
    "palette": "colorblind",
    "figsize": [10, 6],
    "font_scale": 1.5
  },


  "seed": 42,


  "models": 
  {

    "roberta": {
      "tokenizer": {
        "path": "models/tokenizer_bpe/tokenizer",
        "files": "models/tokenizer_bpe/files",
        "max_length": 512,
        "vocab_size": 1028
      },
      "training": {
        "output_dir": "models/RoBERTa/",
        "num_train_epochs": 110,
        "learning_rate": 3e-4,
        "tokenizer_file": "models/tokenizer_gpt2/tokenizer.json",
        "weight_decay": 1e-3,
        "save_steps": 25,
        "logging_dir": "models/RoBERTa/logs/",
        "mlm_probability": 0.15,
        "test_size": 0.2,
        "batch_size": 256
      },
      "model": {
        "max_position_embeddings": 512,
        "num_attention_heads": 4,
        "hidden_size": 256,
        "intermediate_size": 1024,
        "num_hidden_layers": 4,
        "type_vocab_size": 1,
        "is_decoder": false,
        "hidden_dropout_prob": 0.2,
        "attention_probs_dropout_prob": 0.2
      }
    },

  "random_forest": {
    "cv": {
      "n_estimators": [5, 10,  15, 20, 25, 30],
      "max_depth" : [3, 5, 7, 9, 11, 13, 15],
      "max_features" : ["sqrt", "log2"],
      "bootstrap": [true] 
    }
  },

  "sweetnet" : {
    "model":
    {
      "hidden_dim":128
    },

    "training":
    {
      "learning_rate":5E-4,
      "weight_decay":1E-3,
      "num_train_epochs": 100,
      "patience": 50,
      "T_max_scheduler": 50,
      "save_dir": "models/sweetnet/"
    }
  }
}
}
